{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a8372e2",
   "metadata": {},
   "source": [
    "# UPI Number fraud detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d34d6e",
   "metadata": {},
   "source": [
    "## Brief Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeb5e37",
   "metadata": {},
   "source": [
    "# Contents <a id='10'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666e87f",
   "metadata": {},
   "source": [
    "1. [Importing dependecies](#1)\n",
    "2. [Data preprocessing](#2)\n",
    "3. [Statistical Data Analysis](#3)\n",
    "4. [Machine Learning Model building](#4)\n",
    "5. [Training and Evaluation](#5)\n",
    "6. [Hyper-parameter Tuning](#6)\n",
    "7. [Key Observations of Shap and Lime images](#7)\n",
    "8. [Summary](#8)\n",
    "9. [Conclusion](#9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f142d2",
   "metadata": {},
   "source": [
    "## Importing depencies<a id='1'></a> \n",
    "[back to content](#10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "345cc452-84c0-4c2d-a74e-550ae0b73922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pystan\n",
      "  Using cached pystan-3.10.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.6 in d:\\anaconda\\lib\\site-packages (from pystan) (3.10.5)\n",
      "Collecting clikit<0.7,>=0.6 (from pystan)\n",
      "  Using cached clikit-0.6.2-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "INFO: pip is looking at multiple versions of pystan to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pystan\n",
      "  Using cached pystan-3.9.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached pystan-3.9.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached pystan-3.8.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached pystan-3.7.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached pystan-3.6.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached pystan-3.5.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached pystan-3.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "INFO: pip is still looking at multiple versions of pystan to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached pystan-3.3.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-3.2.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-3.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-3.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-3.0.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached pystan-3.0.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-3.0.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-2.19.1.1.tar.gz (16.2 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: Cython!=0.25.1,>=0.22 in d:\\anaconda\\lib\\site-packages (from pystan) (3.0.11)\n",
      "Requirement already satisfied: numpy>=1.7 in d:\\anaconda\\lib\\site-packages (from pystan) (1.26.4)\n",
      "Building wheels for collected packages: pystan\n",
      "  Building wheel for pystan (setup.py): started\n",
      "  Building wheel for pystan (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pystan\n",
      "Failed to build pystan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [4 lines of output]\n",
      "  Warning: MSVC is not supported\n",
      "  C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-install-5b73p4th\\pystan_4a412a60b0ac457abcdd1672665071c6\\setup.py:61: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "    self.version = node.value.s\n",
      "  Cython>=0.22 and NumPy are required.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pystan\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pystan)\n"
     ]
    }
   ],
   "source": [
    "!pip install pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f8f2f7-db88-4c57-a557-9d666fe0d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fb767d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pystan'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpystan\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbayesian_testing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiments\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BinaryDataTest\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pystan'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot\n",
    "import seaborn as sns\n",
    "import pystan\n",
    "from bayesian_testing.experiments import BinaryDataTest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, RidgeCV\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCVa\n",
    "import plotly.colors as colors\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import pickle\n",
    "import shap\n",
    "shap.initjs()\n",
    "import lime\n",
    "from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4523c9",
   "metadata": {},
   "source": [
    "## Data Preprocessing<a id='2'></a> \n",
    "[back to content](#10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dde748",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('upi_fraud_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb9c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2715be",
   "metadata": {},
   "source": [
    "## Statistical Data Analysis<a id='3'></a> \n",
    "<a href='' style=\"float:right\">[back to contents](#10)</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d7e34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92081698",
   "metadata": {},
   "source": [
    "### correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a73f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1317c9",
   "metadata": {},
   "source": [
    "### Finding Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect outliers using Z-score\n",
    "def detect_outliers_zscore(data, threshold=3):\n",
    "    z_scores = (data - data.mean()) / data.std()\n",
    "    outliers = data[np.abs(z_scores) > threshold]\n",
    "    return outliers\n",
    "\n",
    "# Function to detect outliers using IQR\n",
    "def detect_outliers_iqr(data):\n",
    "    q1, q3 = data.quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "outliers_zscore = detect_outliers_zscore(df['trans_amount'])\n",
    "outliers_iqr = detect_outliers_iqr(df['trans_amount'])\n",
    "\n",
    "print(\"Outliers using Z-score:\", outliers_zscore)\n",
    "print(\"Outliers using IQR:\", outliers_iqr)\n",
    "sns.violinplot(y=df['trans_amount'])\n",
    "sns.boxplot(y=df['trans_amount'], whis=np.inf, boxprops={'facecolor': 'none'}, ax=ax)\n",
    "plt.title('Combined Box and Violin Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bbc61a",
   "metadata": {},
   "source": [
    "### Bayesian Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dbcbd2",
   "metadata": {},
   "source": [
    "I am assumming to test if the average transaction amount for fraudulent transactions is significantly different from the average transaction amount for non-fraudulent transactions.\n",
    "\n",
    "**Hypotheses:**\n",
    "\n",
    "**Null Hypothesis (H₀):** The average transaction amount for fraudulent and non-fraudulent transactions is the same.\n",
    "\n",
    "**Alternative Hypothesis (H₁):** The average transaction amount for fraudulent and non-fraudulent transactions is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb1ab35-e849-4031-9ab6-415712c06ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudulent_transactions = df[df['fraud_risk'] == 1]['trans_amount']\n",
    "non_fraudulent_transactions = df[df['fraud_risk'] == 0]['trans_amount']\n",
    "\n",
    "test = BinaryDataTest()\n",
    "test.add_variant_data(\"A\", fraudulent_transactions)\n",
    "test.add_variant_data(\"B\", non_fraudulent_transactions)\n",
    "test.add_variant_data_agg(\"C\", totals=1000, positives=50)\n",
    "\n",
    "# evaluate test:\n",
    "results = test.evaluate()\n",
    "results\n",
    "print(pd.DataFrame(results).set_index('variant').T.to_markdown(tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d06d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudulent_transactions = df[df['fraud_risk'] == 1]['trans_amount']\n",
    "non_fraudulent_transactions = df[df['fraud_risk'] == 0]['trans_amount']\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Priors for the means of the two groups\n",
    "    mu_fraud = pm.Normal('mu_fraud', mu=0, sd=10)\n",
    "    mu_non_fraud = pm.Normal('mu_non_fraud', mu=0, sd=10)\n",
    "\n",
    "    # Shared standard deviation for both groups\n",
    "    sigma = pm.HalfCauchy('sigma', beta=10)\n",
    "\n",
    "    # Likelihood for fraudulent transactions\n",
    "    fraud_likelihood = pm.Normal('fraud_likelihood', mu=mu_fraud, sd=sigma, observed=fraudulent_transactions)\n",
    "\n",
    "    # Likelihood for non-fraudulent transactions\n",
    "    non_fraud_likelihood = pm.Normal('non_fraud_likelihood', mu=mu_non_fraud, sd=sigma, observed=non_fraudulent_transactions)\n",
    "\n",
    "    # Sample from the posterior distribution\n",
    "    trace = pm.sample(1000, tune=1000, cores=1)\n",
    "\n",
    "# Analyze the posterior distribution\n",
    "pm.traceplot(trace)\n",
    "\n",
    "# Calculate the probability that the difference in means is greater than a certain threshold\n",
    "diff_means = trace['mu_fraud'] - trace['mu_non_fraud']\n",
    "prob_diff_greater_than_5 = np.mean(diff_means > 5)  # Adjust the threshold as needed\n",
    "\n",
    "print(f\"Probability that the difference in means is greater than 5: {prob_diff_greater_than_5:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8dfb17-adad-42ea-95ab-cc85fedbc1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudulent_transactions = df[df['fraud_risk'] == 1]['trans_amount'].values\n",
    "non_fraudulent_transactions = df[df['fraud_risk'] == 0]['trans_amount'].values\n",
    "\n",
    "# Define the Stan model\n",
    "stan_model = \"\"\"\n",
    "data {\n",
    "  int<lower=0> N1;\n",
    "  int<lower=0> N2;\n",
    "  vector[N1] y1;\n",
    "  vector[N2] y2;\n",
    "}\n",
    "parameters {\n",
    "  real mu_diff;\n",
    "  real<lower=0> sigma;\n",
    "  real<lower=0> nu;\n",
    "}\n",
    "model {\n",
    "  // Priors\n",
    "  mu_diff ~ normal(0, 10);\n",
    "  sigma ~ cauchy(0, 10);\n",
    "  nu ~ exponential(1/29);\n",
    "\n",
    "  // Likelihood\n",
    "  y1 ~ student_t(nu, mu_diff, sigma);\n",
    "  y2 ~ student_t(nu, 0, sigma);\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Compile the Stan model\n",
    "model = pystan.StanModel(model_code=stan_model)\n",
    "\n",
    "# Prepare data for Stan\n",
    "data = {'N1': len(fraudulent_transactions),\n",
    "        'N2': len(non_fraudulent_transactions),\n",
    "        'y1': fraudulent_transactions,\n",
    "        'y2': non_fraudulent_transactions}\n",
    "\n",
    "# Sample from the posterior distribution\n",
    "fit = model.sampling(data=data, iter=1000, chains=4)\n",
    "\n",
    "# Extract posterior samples\n",
    "diff_means = fit['mu_diff']\n",
    "\n",
    "# Calculate the probability of the alternative hypothesis (H1)\n",
    "prob_h1 = np.mean(diff_means > 0)\n",
    "print(f\"Probability of H1: {prob_h1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2fef68",
   "metadata": {},
   "source": [
    "# Machine Learning Model<a id='4'></a>\n",
    "[back to contents](#10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f8c731",
   "metadata": {},
   "source": [
    "# ML model Training and Evaluation<a id='5'></a>\n",
    "[back to contents](#10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad25dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "features =  df[['trans_hour','trans_day', 'trans_month', 'trans_year', 'category', 'upi_number', 'age', 'trans_amount', 'state', 'zip']]\n",
    "target = df['fraud_risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f6a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, target, random_state = 200, test_size = 0.15)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb692645",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7478ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(x_train_scaled, y_train, x_test_scaled, y_test):\n",
    "    models_list = [\n",
    "        LogisticRegression(),\n",
    "        DecisionTreeClassifier(),\n",
    "        HistGradientBoostingClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        GaussianNB()\n",
    "    ]\n",
    "\n",
    "    for model in models_list:\n",
    "        model.fit(x_train_scaled, y_train)\n",
    "        y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Accuracy of the {model} model: {accuracy:.2f}\")\n",
    "        print(f\"Precision of the {model} model: {precision:.2f}\")\n",
    "        print(f\"Recall of the {model} model: {recall:.2f}\")\n",
    "        print(f\"F1-score of the {model} model: {f1:.2f}\")\n",
    "        print('\\n ________________________________________________ \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_models(x_train_scaled, y_train, x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203aa34d",
   "metadata": {},
   "source": [
    "### **From the above results its very clear that**\n",
    "- **DecisionTreeClassifier**, \n",
    "- **HistGradientBoostingClassifier**, \n",
    "- **RandomForestClassifier**, \n",
    "- **GradientBoostingClassifier**\n",
    "- **AdaBoostClassifier** \n",
    "\n",
    "**are more accurate than the other models with their accuracy greater than 90%. So I will be increasing their performance with the help of Hyperparameter tuning** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c70d3cc",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning <a id='6'></a>\n",
    "[back to contents](#10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e2ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grids for each model\n",
    "param_grid_decision_tree = {\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "param_grid_hist_gradient_boosting = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_leaf_nodes':[10, 20, 15],\n",
    "}\n",
    "\n",
    "param_grid_random_forest = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "param_grid_gradient_boosting = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.1, 0.05, 0.01],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "param_grid_ada_boost = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.1, 0.05, 0.01]\n",
    "}\n",
    "\n",
    "# Create a dictionary to store the models and their parameter grids\n",
    "model_param_grid = {\n",
    "    DecisionTreeClassifier(): param_grid_decision_tree,\n",
    "    HistGradientBoostingClassifier(): param_grid_hist_gradient_boosting,\n",
    "    RandomForestClassifier(): param_grid_random_forest,\n",
    "    GradientBoostingClassifier(): param_grid_gradient_boosting,\n",
    "    AdaBoostClassifier(): param_grid_ada_boost,\n",
    "}\n",
    "results = []\n",
    "# Perform hyperparameter tuning and evaluate models\n",
    "for model, param_grid in model_param_grid.items():\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(x_train_scaled, y_train)\n",
    "    with open(f'best_{model}.pkl', 'wb') as f:  # Open in binary write mode\n",
    "        pickle.dump(grid_search.best_estimator_, f)\n",
    "        print(f\"Best model for {model} saved successfully!\")\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(x_test_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    results.append({'Model': model, 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1})\n",
    "    print(f\"Best parameters for {model}: {grid_search.best_params_}\")\n",
    "    print(f\"Accuracy of the {model} model: {accuracy:.2f}\")\n",
    "    print(f\"Precision of the {model} model: {precision:.2f}\")\n",
    "    print(f\"Recall of the {model} model: {recall:.2f}\")\n",
    "    print(f\"F1-score of the {model} model: {f1:.2f}\")\n",
    "    print('\\n _______________________________________________________________________________________________________________ \\n')\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(best_model)\n",
    "        shap_values = explainer.shap_values(x_test)\n",
    "        print(\"Variable Importance Plot - UPI fraudDetection\")\n",
    "        figure = plt.figure()\n",
    "        shap.summary_plot(shap_values, x_test)\n",
    "    except:\n",
    "        best_model==AdaBoostClassifier()\n",
    "    print('\\n _______________________________________________________________________________________________________________ \\n')\n",
    "    \n",
    "    # SHAP Explanation (for all models)\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(best_model) if isinstance(best_model, (DecisionTreeClassifier, RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier)) else shap.KernelExplainer(best_model.predict, x_train)\n",
    "        shap_values = explainer.shap_values(x_test)\n",
    "        print(\"Variable Importance Plot - UPI fraudDetection\")\n",
    "        shap.summary_plot(shap_values, x_test)\n",
    "    except:\n",
    "        pass  # Handle cases where SHAP explainer might not be applicable\n",
    "\n",
    "    print('\\n _______________________________________________________________________________________________________________ \\n')\n",
    "    # LIME Explanation (for tree-based models)\n",
    "    if isinstance(best_model, (DecisionTreeClassifier, RandomForestClassifier)):\n",
    "        # Get class and feature names (adjust if necessary)\n",
    "        class_names = ['Fraudulent', 'Honest']\n",
    "        feature_names = list(x_train.columns)\n",
    "\n",
    "        # Create LIME explainer\n",
    "        explainer = lime_tabular.LimeTabularExplainer(x_train.values, feature_names=feature_names, class_names=class_names, mode='classification')\n",
    "\n",
    "        # Explain a prediction (modify for specific instance)\n",
    "        instance = x_test.iloc[0]  # Assuming you want to explain the first test instance\n",
    "        explanation = explainer.explain_instance(instance.values, best_model.predict_proba)\n",
    "\n",
    "        # Visualize explanation (adjust for desired visualization)\n",
    "        explanation.show_in_notebook(show_table=True, show_all=False)\n",
    "        plt.show()\n",
    "    # LIME Explanation (for tree-based models)\n",
    "    if isinstance(best_model, (HistGradientBoostingClassifier,GradientBoostingClassifier,AdaBoostClassifier)):\n",
    "        # Get class and feature names (adjust if necessary)\n",
    "        class_names = ['Fraudulent', 'Honest']\n",
    "        feature_names = list(x_train.columns)\n",
    "\n",
    "        # Create LIME explainer\n",
    "        explainer = lime_tabular.LimeTabularExplainer(x_train.values, feature_names=feature_names, class_names=class_names, mode='classification')\n",
    "\n",
    "        # Explain a prediction (modify for specific instance)\n",
    "        instance = x_test.iloc[0]  # Assuming you want to explain the first test instance\n",
    "        explanation = explainer.explain_instance(instance.values, best_model.predict_proba)\n",
    "\n",
    "        # Visualize explanation (adjust for desired visualization)\n",
    "        explanation.show_in_notebook(show_table=True, show_all=False)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d41af8",
   "metadata": {},
   "source": [
    "## Summary of Hyperparameter Tuning Results\n",
    "[back to contents](#10)\n",
    "Hyperparameter Tuning is a technique used to optimize the performance of machine learning models by systematically exploring different combinations of hyperparameters. In this case, we tuned several popular classification models: Decision Tree, HistGradientBoosting, Random Forest, Gradient Boosting, and AdaBoost.\n",
    "\n",
    "Model Performance:\n",
    "\n",
    "1. Decision Tree:\n",
    "    - Best Parameters: max_depth=10, min_samples_leaf=1, min_samples_split=5\n",
    "    - Performance: Achieved an accuracy of 0.95, indicating strong performance.\n",
    "    \n",
    "2. HistGradientBoosting:\n",
    "    - Best Parameters: learning_rate=0.2, max_depth=7, max_leaf_nodes=10\n",
    "    - Performance: Outperformed other models with an accuracy of 0.97 and excellent recall of 0.99.\n",
    "    \n",
    "3. Random Forest:\n",
    "    - Best Parameters: max_depth=None, min_samples_split=2, n_estimators=100\n",
    "    - Performance: Achieved an accuracy of 0.95 and a strong recall of 0.98.\n",
    "4. Gradient Boosting:\n",
    "    - Best Parameters: learning_rate=0.05, max_depth=5, n_estimators=100\n",
    "    - Performance: Showed solid performance with an accuracy of 0.96 and a good recall of 0.98.\n",
    "    \n",
    "5. AdaBoost:\n",
    "    - Best Parameters: learning_rate=0.1, n_estimators=200\n",
    "    - Performance: Achieved an accuracy of 0.94, slightly lower than other models.\n",
    "\n",
    "### **Overall, the HistGradientBoosting model demonstrated the best performance in terms of accuracy and recall. This suggests that it is the most suitable model for this specific classification task. **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b765a",
   "metadata": {},
   "source": [
    "## Key Observations <a id=\"7\"></a>\n",
    "[back to contents](#10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3364b25",
   "metadata": {},
   "source": [
    "### Important features\n",
    " The top features which affect the Risk of Fraud activity are\n",
    " - Transaction Hour\n",
    " - Transaction Day\n",
    " - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "#df_results['Model'] = df_results['Model'].str.replace(r'\\([^()]*\\)', '', regex=True).str.strip()\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3469d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= {'Model': ['DecisionTreeClassifier', 'HistGradientBoostingClassifier', 'RandomForestClassifier', 'GradientBoostingClassifier', 'AdaBoostClassifier'],\n",
    "        'Accuracy': [0.955, 0.97, 0.95, 0.9575, 0.935]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Model', y='Accuracy',data=df)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Model', y='Accuracy', data=df)\n",
    "plt.title('Model Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82239e",
   "metadata": {},
   "source": [
    "# Summary <a id='8'></a>\n",
    "[back to contents](#10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c7f80",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f693b8d",
   "metadata": {},
   "source": [
    "## Conclusion <a id =\"9\"></a>\n",
    "[back to contents](#10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0229fc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
