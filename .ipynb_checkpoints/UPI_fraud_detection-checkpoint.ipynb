{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a8372e2",
   "metadata": {},
   "source": [
    "# UPI Number fraud detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d34d6e",
   "metadata": {},
   "source": [
    "## Brief Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeb5e37",
   "metadata": {},
   "source": [
    "# Contents <a id='10'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666e87f",
   "metadata": {},
   "source": [
    "1. [Importing dependecies](#1)\n",
    "2. [Data preprocessing](#2)\n",
    "3. [Statistical Data Analysis](#3)\n",
    "4. [Machine Learning Model building](#4)\n",
    "5. [Training and Evaluation](#5)\n",
    "6. [Hyper-parameter Tuning](#6)\n",
    "7. [Key Observations of Shap and Lime images](#7)\n",
    "8. [Summary](#8)\n",
    "9. [Conclusion](#9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f142d2",
   "metadata": {},
   "source": [
    "## Importing depencies<a id='1'></a> \n",
    "[back to content](#10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6a59180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.19.5\n",
      "  Downloading numpy-1.19.5.zip (7.3 MB)\n",
      "     ---------------------------------------- 0.0/7.3 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.1/7.3 MB 2.6 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 0.2/7.3 MB 2.9 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.4/7.3 MB 3.4 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 0.8/7.3 MB 4.9 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 0.8/7.3 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 2.0/7.3 MB 7.6 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 2.6/7.3 MB 8.2 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 3.1/7.3 MB 8.7 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 3.7/7.3 MB 9.0 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 4.2/7.3 MB 9.3 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 4.8/7.3 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 5.1/7.3 MB 9.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 5.9/7.3 MB 9.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 6.4/7.3 MB 9.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 6.9/7.3 MB 10.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.3/7.3 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.3/7.3 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.3/7.3 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.3/7.3 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.3/7.3 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.3/7.3 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.3/7.3 MB 7.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [202 lines of output]\n",
      "  setup.py:67: RuntimeWarning: NumPy 1.19.5 may not yet support Python 3.10.\n",
      "    warnings.warn(\n",
      "  Running from numpy source directory.\n",
      "  setup.py:480: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates\n",
      "    run_build = parse_setuppy_commands()\n",
      "  Processing numpy/random\\_bounded_integers.pxd.in\n",
      "  Processing numpy/random\\bit_generator.pyx\n",
      "  Processing numpy/random\\mtrand.pyx\n",
      "  Processing numpy/random\\_bounded_integers.pyx.in\n",
      "  Processing numpy/random\\_common.pyx\n",
      "  Processing numpy/random\\_generator.pyx\n",
      "  Processing numpy/random\\_mt19937.pyx\n",
      "  Processing numpy/random\\_pcg64.pyx\n",
      "  Processing numpy/random\\_philox.pyx\n",
      "  Processing numpy/random\\_sfc64.pyx\n",
      "  Cythonizing sources\n",
      "  blas_opt_info:\n",
      "  blas_mkl_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries mkl_rt not found in ['D:\\\\anaconda\\\\lib', 'C:\\\\', 'D:\\\\anaconda\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  blis_info:\n",
      "    libraries blis not found in ['D:\\\\anaconda\\\\lib', 'C:\\\\', 'D:\\\\anaconda\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_info:\n",
      "    libraries openblas not found in ['D:\\\\anaconda\\\\lib', 'C:\\\\', 'D:\\\\anaconda\\\\libs']\n",
      "  get_default_fcompiler: matching types: '['gnu', 'intelv', 'absoft', 'compaqv', 'intelev', 'gnu95', 'g95', 'intelvem', 'intelem', 'flang']'\n",
      "  customize GnuFCompiler\n",
      "  Could not locate executable g77\n",
      "  Could not locate executable f77\n",
      "  customize IntelVisualFCompiler\n",
      "  Could not locate executable ifort\n",
      "  Could not locate executable ifl\n",
      "  customize AbsoftFCompiler\n",
      "  Could not locate executable f90\n",
      "  customize CompaqVisualFCompiler\n",
      "  Could not locate executable DF\n",
      "  customize IntelItaniumVisualFCompiler\n",
      "  Could not locate executable efl\n",
      "  customize Gnu95FCompiler\n",
      "  Could not locate executable gfortran\n",
      "  Could not locate executable f95\n",
      "  customize G95FCompiler\n",
      "  Could not locate executable g95\n",
      "  customize IntelEM64VisualFCompiler\n",
      "  customize IntelEM64TFCompiler\n",
      "  Could not locate executable efort\n",
      "  Could not locate executable efc\n",
      "  customize PGroupFlangCompiler\n",
      "  Could not locate executable flang\n",
      "  don't know how to compile Fortran code on platform 'nt'\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_blas_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "    libraries tatlas not found in ['D:\\\\anaconda\\\\lib', 'C:\\\\', 'D:\\\\anaconda\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_blas_info:\n",
      "    libraries satlas not found in ['D:\\\\anaconda\\\\lib', 'C:\\\\', 'D:\\\\anaconda\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_blas_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "    libraries ptf77blas,ptcblas,atlas not found in ['D:\\\\anaconda\\\\lib', 'C:\\\\', 'D:\\\\anaconda\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_blas_info:\n",
      "    libraries f77blas,cblas,atlas not found in ['D:\\\\anaconda\\\\lib', 'C:\\\\', 'D:\\\\anaconda\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  accelerate_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-install-7oud1n0g\\numpy_5df5d300c4b140febb71f8191ebe932c\\numpy\\distutils\\system_info.py:1914: UserWarning:\n",
      "      Optimized (vendor) Blas libraries are not found.\n",
      "      Falls back to netlib Blas library which has worse performance.\n",
      "      A better performance should be easily gained by switching\n",
      "      Blas library.\n",
      "    if self._calc_info(blas):\n",
      "  blas_info:\n",
      "    libraries blas not found in ['D:\\\\anaconda\\\\lib', 'C:\\\\', 'D:\\\\anaconda\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-install-7oud1n0g\\numpy_5df5d300c4b140febb71f8191ebe932c\\numpy\\distutils\\system_info.py:1914: UserWarning:\n",
      "      Blas (http://www.netlib.org/blas/) libraries not found.\n",
      "      Directories to search for the libraries can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [blas]) or by setting\n",
      "      the BLAS environment variable.\n",
      "    if self._calc_info(blas):\n",
      "  blas_src_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-install-7oud1n0g\\numpy_5df5d300c4b140febb71f8191ebe932c\\numpy\\distutils\\system_info.py:1914: UserWarning:\n",
      "      Blas (http://www.netlib.org/blas/) sources not found.\n",
      "      Directories to search for the sources can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [blas_src]) or by setting\n",
      "      the BLAS_SRC environment variable.\n",
      "    if self._calc_info(blas):\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  non-existing path in 'numpy\\\\distutils': 'site.cfg'\n",
      "  lapack_opt_info:\n",
      "  lapack_mkl_info:\n",
      "    libraries mkl_rt not found in ['D:\\\\anaconda\\\\lib', 'C:\\\\', 'D:\\\\anaconda\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_lapack_info:\n",
      "    libraries openblas not found in ['D:\\\\anaconda\\\\lib', 'C:\\\\', 'D:\\\\anaconda\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_clapack_info:\n",
      "    libraries openblas,lapack not found in ['D:\\\\anaconda\\\\lib', 'C:\\\\', 'D:\\\\anaconda\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  flame_info:\n",
      "    libraries flame not found in ['D:\\\\anaconda\\\\lib', 'C:\\\\', 'D:\\\\anaconda\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "    libraries lapack_atlas not found in D:\\anaconda\\lib\n",
      "    libraries tatlas,tatlas not found in D:\\anaconda\\lib\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "    libraries tatlas,tatlas not found in C:\\\n",
      "    libraries lapack_atlas not found in D:\\anaconda\\libs\n",
      "    libraries tatlas,tatlas not found in D:\\anaconda\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_info:\n",
      "    libraries lapack_atlas not found in D:\\anaconda\\lib\n",
      "    libraries satlas,satlas not found in D:\\anaconda\\lib\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "    libraries satlas,satlas not found in C:\\\n",
      "    libraries lapack_atlas not found in D:\\anaconda\\libs\n",
      "    libraries satlas,satlas not found in D:\\anaconda\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_3_10_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "    libraries lapack_atlas not found in D:\\anaconda\\lib\n",
      "    libraries ptf77blas,ptcblas,atlas not found in D:\\anaconda\\lib\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "    libraries ptf77blas,ptcblas,atlas not found in C:\\\n",
      "    libraries lapack_atlas not found in D:\\anaconda\\libs\n",
      "    libraries ptf77blas,ptcblas,atlas not found in D:\\anaconda\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_threads_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_info:\n",
      "    libraries lapack_atlas not found in D:\\anaconda\\lib\n",
      "    libraries f77blas,cblas,atlas not found in D:\\anaconda\\lib\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "    libraries f77blas,cblas,atlas not found in C:\\\n",
      "    libraries lapack_atlas not found in D:\\anaconda\\libs\n",
      "    libraries f77blas,cblas,atlas not found in D:\\anaconda\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  lapack_info:\n",
      "    libraries lapack not found in ['D:\\\\anaconda\\\\lib', 'C:\\\\', 'D:\\\\anaconda\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-install-7oud1n0g\\numpy_5df5d300c4b140febb71f8191ebe932c\\numpy\\distutils\\system_info.py:1748: UserWarning:\n",
      "      Lapack (http://www.netlib.org/lapack/) libraries not found.\n",
      "      Directories to search for the libraries can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [lapack]) or by setting\n",
      "      the LAPACK environment variable.\n",
      "    return getattr(self, '_calc_info_{}'.format(name))()\n",
      "  lapack_src_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-install-7oud1n0g\\numpy_5df5d300c4b140febb71f8191ebe932c\\numpy\\distutils\\system_info.py:1748: UserWarning:\n",
      "      Lapack (http://www.netlib.org/lapack/) sources not found.\n",
      "      Directories to search for the sources can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [lapack_src]) or by setting\n",
      "      the LAPACK_SRC environment variable.\n",
      "    return getattr(self, '_calc_info_{}'.format(name))()\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  numpy_linalg_lapack_lite:\n",
      "    FOUND:\n",
      "      language = c\n",
      "      define_macros = [('HAVE_BLAS_ILP64', None), ('BLAS_SYMBOL_SUFFIX', '64_')]\n",
      "  \n",
      "  C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-obp9zri_\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:275: UserWarning: Unknown distribution option: 'define_macros'\n",
      "    warnings.warn(msg)\n",
      "  running dist_info\n",
      "  running build_src\n",
      "  build_src\n",
      "  building py_modules sources\n",
      "  creating build\n",
      "  creating build\\src.win-amd64-3.10\n",
      "  creating build\\src.win-amd64-3.10\\numpy\n",
      "  creating build\\src.win-amd64-3.10\\numpy\\distutils\n",
      "  building library \"npymath\" sources\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb767d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"D:\\anaconda\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"D:\\anaconda\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"D:\\anaconda\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"D:\\anaconda\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n",
      "    handle._run()\n",
      "  File \"D:\\anaconda\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_2460\\4101722578.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\__init__.py\", line 39, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"D:\\anaconda\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"D:\\anaconda\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"D:\\anaconda\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"D:\\anaconda\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n",
      "    handle._run()\n",
      "  File \"D:\\anaconda\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_2460\\4101722578.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\dtypes\\dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"D:\\anaconda\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"D:\\anaconda\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"D:\\anaconda\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"D:\\anaconda\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n",
      "    handle._run()\n",
      "  File \"D:\\anaconda\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_2460\\4101722578.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"D:\\anaconda\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"D:\\anaconda\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"D:\\anaconda\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"D:\\anaconda\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"D:\\anaconda\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n",
      "    handle._run()\n",
      "  File \"D:\\anaconda\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_2460\\4101722578.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\arrays\\masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"D:\\anaconda\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"D:\\anaconda\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"D:\\anaconda\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"D:\\anaconda\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"D:\\anaconda\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n",
      "    handle._run()\n",
      "  File \"D:\\anaconda\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_2460\\4101722578.py\", line 3, in <module>\n",
      "    import matplotlib.pyplot\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\matplotlib\\__init__.py\", line 131, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\matplotlib\\colors.py\", line 56, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\matplotlib\\scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\matplotlib\\ticker.py\", line 138, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\matplotlib\\transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpymc3\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpm\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\__init__.py:131\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\rcsetup.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\colors.py:56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\scale.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[0;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[0;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\ticker.py:138\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[0;32m    140\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    142\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    143\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    151\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\transforms.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot\n",
    "import seaborn as sns\n",
    "import pymc3 as pm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, RidgeCV\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import plotly.colors as colors\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import pickle\n",
    "import shap\n",
    "shap.initjs()\n",
    "import lime\n",
    "from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4523c9",
   "metadata": {},
   "source": [
    "## Data Preprocessing<a id='2'></a> \n",
    "[back to content](#10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dde748",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('upi_fraud_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb9c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2715be",
   "metadata": {},
   "source": [
    "## Statistical Data Analysis<a id='3'></a> \n",
    "<a href='' style=\"float:right\">[back to contents](#10)</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d7e34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92081698",
   "metadata": {},
   "source": [
    "### correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a73f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1317c9",
   "metadata": {},
   "source": [
    "### Finding Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect outliers using Z-score\n",
    "def detect_outliers_zscore(data, threshold=3):\n",
    "    z_scores = (data - data.mean()) / data.std()\n",
    "    outliers = data[np.abs(z_scores) > threshold]\n",
    "    return outliers\n",
    "\n",
    "# Function to detect outliers using IQR\n",
    "def detect_outliers_iqr(data):\n",
    "    q1, q3 = data.quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "outliers_zscore = detect_outliers_zscore(df['trans_amount'])\n",
    "outliers_iqr = detect_outliers_iqr(df['trans_amount'])\n",
    "\n",
    "print(\"Outliers using Z-score:\", outliers_zscore)\n",
    "print(\"Outliers using IQR:\", outliers_iqr)\n",
    "sns.violinplot(y=df['trans_amount'])\n",
    "sns.boxplot(y=df['trans_amount'], whis=np.inf, boxprops={'facecolor': 'none'}, ax=ax)\n",
    "plt.title('Combined Box and Violin Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bbc61a",
   "metadata": {},
   "source": [
    "### Bayesian Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dbcbd2",
   "metadata": {},
   "source": [
    "I am assumming to test if the average transaction amount for fraudulent transactions is significantly different from the average transaction amount for non-fraudulent transactions.\n",
    "\n",
    "**Hypotheses:**\n",
    "\n",
    "**Null Hypothesis (H₀):** The average transaction amount for fraudulent and non-fraudulent transactions is the same.\n",
    "\n",
    "**Alternative Hypothesis (H₁):** The average transaction amount for fraudulent and non-fraudulent transactions is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d06d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudulent_transactions = df[df['fraud_risk'] == 1]['trans_amount']\n",
    "non_fraudulent_transactions = df[df['fraud_risk'] == 0]['trans_amount']\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Priors for the means of the two groups\n",
    "    mu_fraud = pm.Normal('mu_fraud', mu=0, sd=10)\n",
    "    mu_non_fraud = pm.Normal('mu_non_fraud', mu=0, sd=10)\n",
    "\n",
    "    # Shared standard deviation for both groups\n",
    "    sigma = pm.HalfCauchy('sigma', beta=10)\n",
    "\n",
    "    # Likelihood for fraudulent transactions\n",
    "    fraud_likelihood = pm.Normal('fraud_likelihood', mu=mu_fraud, sd=sigma, observed=fraudulent_transactions)\n",
    "\n",
    "    # Likelihood for non-fraudulent transactions\n",
    "    non_fraud_likelihood = pm.Normal('non_fraud_likelihood', mu=mu_non_fraud, sd=sigma, observed=non_fraudulent_transactions)\n",
    "\n",
    "    # Sample from the posterior distribution\n",
    "    trace = pm.sample(1000, tune=1000, cores=1)\n",
    "\n",
    "# Analyze the posterior distribution\n",
    "pm.traceplot(trace)\n",
    "\n",
    "# Calculate the probability that the difference in means is greater than a certain threshold\n",
    "diff_means = trace['mu_fraud'] - trace['mu_non_fraud']\n",
    "prob_diff_greater_than_5 = np.mean(diff_means > 5)  # Adjust the threshold as needed\n",
    "\n",
    "print(f\"Probability that the difference in means is greater than 5: {prob_diff_greater_than_5:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2fef68",
   "metadata": {},
   "source": [
    "# Machine Learning Model<a id='4'></a>\n",
    "[back to contents](#10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f8c731",
   "metadata": {},
   "source": [
    "# ML model Training and Evaluation<a id='5'></a>\n",
    "[back to contents](#10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad25dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "features =  df[['trans_hour','trans_day', 'trans_month', 'trans_year', 'category', 'upi_number', 'age', 'trans_amount', 'state', 'zip']]\n",
    "target = df['fraud_risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f6a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, target, random_state = 200, test_size = 0.15)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb692645",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7478ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(x_train_scaled, y_train, x_test_scaled, y_test):\n",
    "    models_list = [\n",
    "        LogisticRegression(),\n",
    "        DecisionTreeClassifier(),\n",
    "        HistGradientBoostingClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        GaussianNB()\n",
    "    ]\n",
    "\n",
    "    for model in models_list:\n",
    "        model.fit(x_train_scaled, y_train)\n",
    "        y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Accuracy of the {model} model: {accuracy:.2f}\")\n",
    "        print(f\"Precision of the {model} model: {precision:.2f}\")\n",
    "        print(f\"Recall of the {model} model: {recall:.2f}\")\n",
    "        print(f\"F1-score of the {model} model: {f1:.2f}\")\n",
    "        print('\\n ________________________________________________ \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_models(x_train_scaled, y_train, x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203aa34d",
   "metadata": {},
   "source": [
    "### **From the above results its very clear that**\n",
    "- **DecisionTreeClassifier**, \n",
    "- **HistGradientBoostingClassifier**, \n",
    "- **RandomForestClassifier**, \n",
    "- **GradientBoostingClassifier**\n",
    "- **AdaBoostClassifier** \n",
    "\n",
    "**are more accurate than the other models with their accuracy greater than 90%. So I will be increasing their performance with the help of Hyperparameter tuning** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c70d3cc",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning <a id='6'></a>\n",
    "[back to contents](#10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e2ddfe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the parameter grids for each model\n",
    "param_grid_decision_tree = {\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "param_grid_hist_gradient_boosting = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_leaf_nodes':[10, 20, 15],\n",
    "}\n",
    "\n",
    "param_grid_random_forest = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "param_grid_gradient_boosting = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.1, 0.05, 0.01],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "param_grid_ada_boost = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.1, 0.05, 0.01]\n",
    "}\n",
    "\n",
    "# Create a dictionary to store the models and their parameter grids\n",
    "model_param_grid = {\n",
    "    DecisionTreeClassifier(): param_grid_decision_tree,\n",
    "    HistGradientBoostingClassifier(): param_grid_hist_gradient_boosting,\n",
    "    RandomForestClassifier(): param_grid_random_forest,\n",
    "    GradientBoostingClassifier(): param_grid_gradient_boosting,\n",
    "    AdaBoostClassifier(): param_grid_ada_boost,\n",
    "}\n",
    "results = []\n",
    "# Perform hyperparameter tuning and evaluate models\n",
    "for model, param_grid in model_param_grid.items():\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(x_train_scaled, y_train)\n",
    "    with open(f'best_{model}.pkl', 'wb') as f:  # Open in binary write mode\n",
    "        pickle.dump(grid_search.best_estimator_, f)\n",
    "        print(f\"Best model for {model} saved successfully!\")\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(x_test_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    results.append({'Model': model, 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1})\n",
    "    print(f\"Best parameters for {model}: {grid_search.best_params_}\")\n",
    "    print(f\"Accuracy of the {model} model: {accuracy:.2f}\")\n",
    "    print(f\"Precision of the {model} model: {precision:.2f}\")\n",
    "    print(f\"Recall of the {model} model: {recall:.2f}\")\n",
    "    print(f\"F1-score of the {model} model: {f1:.2f}\")\n",
    "    print('\\n _______________________________________________________________________________________________________________ \\n')\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(best_model)\n",
    "        shap_values = explainer.shap_values(x_test)\n",
    "        print(\"Variable Importance Plot - UPI fraudDetection\")\n",
    "        figure = plt.figure()\n",
    "        shap.summary_plot(shap_values, x_test)\n",
    "    except:\n",
    "        best_model==AdaBoostClassifier()\n",
    "    print('\\n _______________________________________________________________________________________________________________ \\n')\n",
    "    \n",
    "    # SHAP Explanation (for all models)\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(best_model) if isinstance(best_model, (DecisionTreeClassifier, RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier)) else shap.KernelExplainer(best_model.predict, x_train)\n",
    "        shap_values = explainer.shap_values(x_test)\n",
    "        print(\"Variable Importance Plot - UPI fraudDetection\")\n",
    "        shap.summary_plot(shap_values, x_test)\n",
    "    except:\n",
    "        pass  # Handle cases where SHAP explainer might not be applicable\n",
    "\n",
    "    print('\\n _______________________________________________________________________________________________________________ \\n')\n",
    "    # LIME Explanation (for tree-based models)\n",
    "    if isinstance(best_model, (DecisionTreeClassifier, RandomForestClassifier)):\n",
    "        # Get class and feature names (adjust if necessary)\n",
    "        class_names = ['Fraudulent', 'Honest']\n",
    "        feature_names = list(x_train.columns)\n",
    "\n",
    "        # Create LIME explainer\n",
    "        explainer = lime_tabular.LimeTabularExplainer(x_train.values, feature_names=feature_names, class_names=class_names, mode='classification')\n",
    "\n",
    "        # Explain a prediction (modify for specific instance)\n",
    "        instance = x_test.iloc[0]  # Assuming you want to explain the first test instance\n",
    "        explanation = explainer.explain_instance(instance.values, best_model.predict_proba)\n",
    "\n",
    "        # Visualize explanation (adjust for desired visualization)\n",
    "        explanation.show_in_notebook(show_table=True, show_all=False)\n",
    "        plt.show()\n",
    "    # LIME Explanation (for tree-based models)\n",
    "    if isinstance(best_model, (HistGradientBoostingClassifier,GradientBoostingClassifier,AdaBoostClassifier)):\n",
    "        # Get class and feature names (adjust if necessary)\n",
    "        class_names = ['Fraudulent', 'Honest']\n",
    "        feature_names = list(x_train.columns)\n",
    "\n",
    "        # Create LIME explainer\n",
    "        explainer = lime_tabular.LimeTabularExplainer(x_train.values, feature_names=feature_names, class_names=class_names, mode='classification')\n",
    "\n",
    "        # Explain a prediction (modify for specific instance)\n",
    "        instance = x_test.iloc[0]  # Assuming you want to explain the first test instance\n",
    "        explanation = explainer.explain_instance(instance.values, best_model.predict_proba)\n",
    "\n",
    "        # Visualize explanation (adjust for desired visualization)\n",
    "        explanation.show_in_notebook(show_table=True, show_all=False)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d41af8",
   "metadata": {},
   "source": [
    "## Summary of Hyperparameter Tuning Results\n",
    "[back to contents](#10)\n",
    "Hyperparameter Tuning is a technique used to optimize the performance of machine learning models by systematically exploring different combinations of hyperparameters. In this case, we tuned several popular classification models: Decision Tree, HistGradientBoosting, Random Forest, Gradient Boosting, and AdaBoost.\n",
    "\n",
    "Model Performance:\n",
    "\n",
    "1. Decision Tree:\n",
    "    - Best Parameters: max_depth=10, min_samples_leaf=1, min_samples_split=5\n",
    "    - Performance: Achieved an accuracy of 0.95, indicating strong performance.\n",
    "    \n",
    "2. HistGradientBoosting:\n",
    "    - Best Parameters: learning_rate=0.2, max_depth=7, max_leaf_nodes=10\n",
    "    - Performance: Outperformed other models with an accuracy of 0.97 and excellent recall of 0.99.\n",
    "    \n",
    "3. Random Forest:\n",
    "    - Best Parameters: max_depth=None, min_samples_split=2, n_estimators=100\n",
    "    - Performance: Achieved an accuracy of 0.95 and a strong recall of 0.98.\n",
    "4. Gradient Boosting:\n",
    "    - Best Parameters: learning_rate=0.05, max_depth=5, n_estimators=100\n",
    "    - Performance: Showed solid performance with an accuracy of 0.96 and a good recall of 0.98.\n",
    "    \n",
    "5. AdaBoost:\n",
    "    - Best Parameters: learning_rate=0.1, n_estimators=200\n",
    "    - Performance: Achieved an accuracy of 0.94, slightly lower than other models.\n",
    "\n",
    "### **Overall, the HistGradientBoosting model demonstrated the best performance in terms of accuracy and recall. This suggests that it is the most suitable model for this specific classification task. **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b765a",
   "metadata": {},
   "source": [
    "## Key Observations <a id=\"7\"></a>\n",
    "[back to contents](#10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3364b25",
   "metadata": {},
   "source": [
    "### Important features\n",
    " The top features which affect the Risk of Fraud activity are\n",
    " - Transaction Hour\n",
    " - Transaction Day\n",
    " - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "#df_results['Model'] = df_results['Model'].str.replace(r'\\([^()]*\\)', '', regex=True).str.strip()\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3469d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= {'Model': ['DecisionTreeClassifier', 'HistGradientBoostingClassifier', 'RandomForestClassifier', 'GradientBoostingClassifier', 'AdaBoostClassifier'],\n",
    "        'Accuracy': [0.955, 0.97, 0.95, 0.9575, 0.935]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Model', y='Accuracy',data=df)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Model', y='Accuracy', data=df)\n",
    "plt.title('Model Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82239e",
   "metadata": {},
   "source": [
    "# Summary <a id='8'></a>\n",
    "[back to contents](#10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c7f80",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f693b8d",
   "metadata": {},
   "source": [
    "## Conclusion <a id =\"9\"></a>\n",
    "[back to contents](#10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0229fc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
